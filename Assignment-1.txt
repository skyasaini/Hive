# creating a sales_order_data.csv file into local
vim sales_order_data.csv

# coping row data from https://raw.githubusercontent.com/shashank-mishra219/Hive-Class/main/sales_order_data.csv

# copying sales_order_data.csv file into hadoop file system
hdfs dfs -put /home/cloudera/sales_order_data.csv /tmp/hive_data/

# checkinhg file in the hadoop
hdfs dfs -ls /tmp/hive_data/

# starting hive
# Creating a internal hive table "sales_order_csv" which will store csv data sales_order.csv from hdfs location

create table sales_order_csv  
(
ORDERNUMBER int,
QUANTITYORDERED int,
PRICEEACH float,
ORDERLINENUMBER int,
SALES float,
STATUS string,
QTR_ID int,
MONTH_ID int,
YEAR_ID int,
PRODUCTLINE string,
MSRP int,
PRODUCTCODE string,
PHONE string,
CITY string,
STATE string,
POSTALCODE string,
COUNTRY string,
TERRITORY string,
CONTACTLASTNAME string,
CONTACTFIRSTNAME string,
DEALSIZE string
)
row format delimited
fields terminated by ','
tblproperties("skip.header.line.count"="1"); 

# Loading  data from hdfs path into "sales_order_csv" 

load data inpath '/tmp/hive_data/sales_order_data.csv' into table sales_order_csv;

# Display column name
set hive.cli.print.header = true;

# checking data in the sales_order_csv table
select * from sales_order_csv limit 10

# Creating an internal hive table which will store data in ORC format "sales_order_orc"

create table sales_order_orc
(
ORDERNUMBER int,
QUANTITYORDERED int,
PRICEEACH float,
ORDERLINENUMBER int,
SALES float,
STATUS string,
QTR_ID int,
MONTH_ID int,
YEAR_ID int,
PRODUCTLINE string,
MSRP int,
PRODUCTCODE string,
PHONE string,
CITY string,
STATE string,
POSTALCODE string,
COUNTRY string,
TERRITORY string,
CONTACTLASTNAME string,
CONTACTFIRSTNAME string,
DEALSIZE string
)
stored as orc;

# Loading data from "sales_order_csv" into "sales_order_orc"

from sales_order_csv insert overwrite table sales_order_orc select *;

# checking data in table sales_order_orc

select * from sales_order_orc limit 10














